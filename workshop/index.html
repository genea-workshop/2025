<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>GENEA Workshop 2025
  </title>

  <!-- Bootstrap core CSS -->
  <link href="/2025/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
  <link href="/2025/vendor/fontawesome-free/css/all.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="/2025/css/iva.min.css" rel="stylesheet">
  <style>
    .announcement-box {
      background-color: rgba(125, 188, 255, 0.4);
      color: #777;
      font-size: 14px;
      line-height: 23px;
      padding: 13px 16px;
      text-align: justify;
      font-family:Arial, Helvetica, sans-serif;
      border-radius: 10px;
    }
  
    .announcement-box .badge {
    background-color: #A14D3A;
    color: #fff;
    font-weight:bold;
    text-transform: uppercase;
    text-align: center;
    }
  </style>
</head>

<body id="page-top">

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">GENEA Challenge 2025</span>
      <!-- <span class="d-none d-lg-block">
        <img src="img/avatar.png" class="img-fluid img-profile rounded-circle mx-auto mb-5" alt="">

      </span> -->
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#home">Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#important-dates">Important dates</a>
        </li>

        <!-- <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#workshop-programme"><b>Workshop programme</b></a>
        </li> -->

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#call-for-papers">Call for papers</a>
        </li>

        <!-- <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#call-for-posters">Call for posters</a>
        </li> -->

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#reproducibility-award">Reproducibility Award</a>
        </li>

         <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#invited-speakers">Invited speakers</a>
        </li>

        <!--<li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#accepted-papers">Accepted papers</a>
        </li> -->

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#organising-committee">Organising committee</a>
        </li>
        <!--
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#program-committee">Program committee</a>
        </li>
      -->
      <li class="nav-item">
        <a class="nav-link js-scroll-trigger" href="#join-our-community">Join our community</a>
      </li>
      </ul>
    </div>
  </nav>


  <div class="container-fluid p-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="home">
      <div class="w-100">
        <div class="row">
          <div class="col-md-9 col-sm-12">
            <div> <img src="/2025/img/GENEA_logo.png" class="img-fluid rounded" class="mt-2" width=300 alt="GENEA"
                title="GENEA"> </div>
            <div>
              <h2 class="mb-2">
                Workshop 2025
              </h2>
            </div>

            <div class="subheading mb-5">Generation and Evaluation of Non-verbal Behaviour for Embodied Agents</div>

            <!-- <p class="mb-5">
            <div class="col-sm-12 col-md-12">
              <div class="row">
              <div class="announcement-box">
                <span class="badge">Announcement</span>
                ðŸ“¢ <strong>Call for Posters</strong> now open! Submit your work by <strong>September 30, 2025</strong>.
                    <a href="#call-for-posters">Click here for more details</a>.
              </div>
              </div>
            </div>
            </p> -->

            <p class="mb-5">
              <b>Official <a href="https://acmmm2025.org/" target="_blank">ACM Multimedia 2025</a> Workshop â€“ October 27 or 28, 2025 (in person)
              </b><br><br>

              The GENEA (Generation and Evaluation of Non-verbal Behaviour for Embodied Agents) Workshop 2025 aims to bring together
              researchers from diverse disciplines working on different aspects of non-verbal behaviour generation, facilitating
              discussions on advancing both generation techniques and evaluation methodologies.
              We invite contributions from fields such as human-computer interaction, machine learning, multimedia, robotics, computer
              graphics, and social sciences. This is the sixth installment of the GENEA Workshop,
              for more information about the 2024 installment, please go <a
                href="https://genea-workshop.github.io/2024/" target="_blank">here</a>.<br><br>


            </p>
            <div class="row justify-content-center">

              <img src="/2025/img/avatar.png" class="img-fluid rounded" class="mt-2" width=300 alt="">
            </div>
          </div>
          <div class="col-md-3 d-none d-md-block">
            <a class="twitter-timeline" href="https://twitter.com/genea_workshop?ref_src=twsrc%5Etfw">Tweets by genea_workshop</a>
            <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
          </div>
        </div>
      </div>

    </section>

    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="important-dates">
      <div class="w-100">
        <h2 class="mb-5">Important dates </h2>
        <p>Submission Deadlines: All deadlines are set at the end of the day, <a
            href="https://en.wikipedia.org/wiki/Anywhere_on_Earth">Anywhere on Earth (AoE)</a></p>
        <div class="row">
          <div class="col">July 9, 2025</div>
          <div class="col">Paper abstract deadline</div>
        </div>
        <div class="row">
          <div class="col">July 11, 2025</div>
          <div class="col">Submission deadline</div>
        </div>
        <div class="row">
          <div class="col">August 01, 2025</div>
          <div class="col">Notification of paper acceptance</div>
        </div>
        <div class="row">
          <div class="col">August 10, 2025</div>
          <div class="col">Camera-ready deadline</div>
        </div>
        <div class="row">
          <div class="col">Sept 19, 2025</div>
          <div class="col">Poster-session submission deadline</div>
        </div>
        <div class="row">
          <div class="col">Oct 3, 2023</div>
          <div class="col">Notification of poster acceptance</div>
        </div>
        <div class="row">
          <div class="col">Oct 27 or 28, 2025</div>
          <div class="col">In-person workshop at ACM Multimedia</div>
        </div>
    </section>

    <!-- <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="workshop-programme">
      <div class="w-100">
        <h2 class="mb-5">Planned Workshop programme</h2>
        <h4>ALL TIMES IN SAN JOSE' LOCAL TIMEZONE (UTC-6)</h4>
        <div>The Workshop presentations will take place at ICMI in San JosÃ© on November 4th.</div>
        
        <div class="row">
          <div class="col">09:30&nbsp;-&nbsp;09:40</div>
          <div class="col-10"><b>Opening statement</b></div>
        </div>

        <div class="row">
          <div class="col">09:40&nbsp;-&nbsp;10:30</div>
          <div class="col-10"><b>Keynote presentation by Stacy Marsella (Northeastern's Khoury College of Computer Sciences, Boston)</b></div>
        </div>

        <div class="row">
          <div class="col">10:30&nbsp;-&nbsp;11:30</div>
          <div class="col-10"><b>Workshop paper presentations part I</b></div>
        </div>
        <div class="row">
          <ul style="list-style: none">
            <li><span style="margin-right: 10px;"> </span> Gesture Evaluation in Virtual Reality (Deichler et al.)</li>
            <li><span style="margin-right: 10px;"> </span> Gesture Area Coverage to Assess Gesture Expressiveness and Human-Likeness (Tonoli et al.)</li>
            <li><span style="margin-right: 10px;"> </span> Benchmarking Speech-Driven Gesture Generation Models for Generalization to Unseen Voices and Noisy Environments (GÃ³mez SÃ¡nchez et al.)</li>
          </ul>
        </div>
        
        <div class="row">
          <div class="col">11:30&nbsp;-&nbsp;13:00</div>
          <div class="col-10"><b>Lunch break</b></div>
        </div>

        <div class="row">
          <div class="col">13:00&nbsp;-&nbsp;13:50</div>
          <div class="col-10"><b>Keynote presentation by Yukiko Nakano (Seikei University, Tokyo)</b></div>
        </div>

        <div class="row">
          <div class="col">13:50&nbsp;-&nbsp;14:30</div>
          <div class="col-10"><b>Break / Poster session</b></div>
        </div>

        <div class="row">
          <div class="col">14:30&nbsp;-&nbsp;15:10</div>
          <div class="col-10"><b>Workshop paper presentations part II</b></div>
        </div>
        <div class="row">
          <ul style="list-style: none">
            <li><span style="margin-right: 10px;"> </span> Towards interpretable co-speech gestures synthesis using STARGATE (Abel et al.)</li>
            <li><span style="margin-right: 10px;"> </span> Qualitative study of gesture annotation corpus: Challenges and perspectives (Grondin Verdon et al.)</li>
          </ul>
        </div>

        <div class="row">
          <div class="col"> 15:10&nbsp;-&nbsp;16:10</a> </div>
          <div class="col-10"><b>Panel discussion</b></div>
        </div>
        <div class="row">
          <ul style="list-style: none">
            <li><span style="margin-right: 10px;"> </span>Sean Andrist, Stacy Marsella, Yukiko Nakano and Yaser Sheikh</li>
          </ul>
        </div>
      
        <div class="row">
          <div class="col">16:10&nbsp;-&nbsp;16:30</div>
          <div class="col-10"><b>Break</b></div>
        </div>

        <div class="row">
          <div class="col">16:30&nbsp;-&nbsp;16:50</div>
          <div class="col-10"><b>GENEA Leaderboard presentation</b></div>
        </div>

        <div class="row">
          <div class="col">16:50&nbsp;-&nbsp;17:50</div>
          <div class="col-10"><b>Group discussion</b></div>
        </div>

        <div class="row">
          <div class="col">17:50&nbsp;-&nbsp;18:00</div>
          <div class="col-10"><b>Closing remarks (announce award winner)</b></div>
        </div>

      </div>

    </section> -->

    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="call-for-papers">

      <div class="w-100">
        <h2 class="mb-5">Call for papers</h2>

        <div class="iva-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <!-- <div class="iva-content">
            <h4>Comming Soon!</h4>
            <p>
              We are currently preparing our Call for Papers and will update this section shortly with all the details. 
              We look forward to receiving your paper submissions. Stay tuned for updates!
            </p>
          </div> -->

          <div class="iva-content">
            <p>GENEA 2025 is the sixth GENEA Workshop and an official workshop of ACM MM â€™25, which will take place in Dublin,
              Ireland. Accepted paper submissions will be included in dedicated proceedings by the ACM.</p>
            
            <p>Generating non-verbal behaviours, such as gesticulation, facial expressions and gaze, is of great importance for
              natural interaction with embodied agents such as virtual agents and social robots. At present, behaviour generation is
              typically powered by rule-based systems, data-driven approaches like generative AI, or their hybrids. For evaluation,
              both objective and subjective methods exist, but their application and validity are frequently a point of contention.
            </p>
            
            <p>The aim of the GENEA Workshop is to bring together researchers working on the generation and evaluation of non-verbal
              behaviours for embodied agents. The goal is to</p>
            
            
            <ul>
              <li>facilitate knowledge transfer and discussion across different communities and research fields;</li>
              <li>promote data, resources, evaluation, and reproducibility, also evolving best practices in these areas; and</li>
              <li>provide an inclusive environment where new and established researchers can learn from each other.</li>
            </ul>
            
            <p>To kickstart this process, we invite all interested researchers to submit a paper or a poster for presentation at the
              workshop, and to attend the event.</p>

            <h4>Paper topics include (but are not limited to) the following</h4>
            <ul>
              <li>Automated synthesis of facial expressions, gestures, and gaze movements, including multi-modal synthesis</li>
              <li>Audio-, music- and emotion-driven or stylistic non-verbal behaviour synthesis</li>
              <li>Closed-loop/end-to-end non-verbal behaviour generation (from perception to action)</li>
              <li>Non-verbal behaviour synthesis in two-party and group interactions</li>
              <li>Using LLMs/VLMs in the context of non-verbal behaviour synthesis</li>
              <li>New datasets, annotation methods, and analyses of existing datasets related to non-verbal behaviour</li>
              <li>Cross-cultural and multilingual influences on non-verbal behaviour generation</li>
              <li>Cognitive and affective models for non-verbal behaviour generation</li>
              <li>Social perception and attribution of synthesised non-verbal behaviour</li>
              <li>Ethical considerations and biases in non-verbal behaviour synthesis</li>
              <li>Subjective and objective evaluation methods for all of the above topics</li>
            </ul>
            
            <h4>Submission guidelines</h4>
            <p>We will accept <b>long</b> (8 pages) and <b>short</b> (4 pages) paper submissions, all in the same double-column <a
                href="https://acmmm2025.org/call-for-papers/"  target="_blank">ACM conference
                format</a> as used by ACM MM . Pages containing only references do not
              count toward the page limit for any of the paper types. Submissions should be made in PDF format through OpenReview
              and formatted for double-blind review.</p>
       
            <p><b>Submission site:</b>
              <a href="https://openreview.net/group?id=acmmm.org/ACMMM/2025/Workshop/GENEA"> https://openreview.net/group?id=acmmm.org/ACMMM/2025/Workshop/GENEA</a>
            </p>

            <p>To encourage authors to make their work reproducible and reward the effort that this requires, we have
              introduced the <a class="js-scroll-trigger" href="#reproducibility-award">GENEA Workshop Reproducibility Award</a>.
            </p>

            <p>We will also host an <b>open poster session</b> for advertising your late-breaking results and already-published work to the community. 
              No paper submission is needed to participate in the poster session, and these posters will not be part of any proceedings (non archival). 
              Submission guidelines for the poster session will be available on the workshop website.
            </p>
          </div>
        </div>
      </div>
    </section>


    <!-- <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="call-for-posters">
    
      <div class="w-100">
        <h2 class="mb-5">Call for posters</h2>
    
        <div class="iva-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="iva-content">
            <p>The GENEA Workshop at ACM ICMI 2025 will host an open poster session for advertising your late-breaking
              results and recently-published work to the community. Only a poster submission is required, no paper
              submission is needed to participate in the poster session, and these posters will not be part of any
              proceedings (i.e., non-archival). However, poster presentation does require a valid registration with ICMI to
              attend the workshop, and is subject to space constraints.</p>
    
            <h4>Paper topics include (but are not limited to) the following</h4>
            <ul>
              <li>Automated synthesis of facial expressions, gestures, and gaze movements</li>
              <li>Audio- and music-driven nonverbal behaviour synthesis</li>
              <li>Closed-loop nonverbal behaviour generation (from perception to action)</li>
              <li>Nonverbal behaviour synthesis in two-party and group interactions</li>
              <li>Emotion-driven and stylistic nonverbal behaviour synthesis</li>
              <li>New datasets related to nonverbal behaviour</li>
              <li>Believable nonverbal behaviour synthesis using motion-capture and 4D scan data</li>
              <li>Multi-modal nonverbal behaviour synthesis</li>
              <li>Interactive/autonomous nonverbal behavior generation</li>
              <li>LLMs and foundation models in the context of non-verbal behaviour synthesis</li>
              <li>Subjective and objective evaluation methods for nonverbal behaviour synthesis</li>
              <li>Guidelines for nonverbal behaviours in human-agent interaction</li>
            </ul>
    
            <h3>Poster guidelines</h3>
            <ul>
              <li>Poster format: 1-page poster (no larger than A0 size; portrait is recommended). There is no specific
                template. The poster can be designed as you want.
              </li>
              <li>How to submit: Please submit your poster draft (in PDF format) and/or poster abstract <a
                  href="https://forms.gle/mxJ6uTGbXS8gb9169">here (https://forms.gle/mxJ6uTGbXS8gb9169)</a>. We will
                acknowledge your submission within 24 hours. The submission deadline is 23:59, September 30, 2025 (Anywhere
                on Earth timezone). We will get back to you no later than October 15 to let you know if we are able to
                accommodate your poster at the event.</li>
            </ul>
          </div>
        </div>
      </div>
    </section> -->

    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="reproducibility-award">

      <div class="w-100">
        <h2 class="mb-5">Reproducibility Award</h2>
        Reproducibility is a cornerstone of the scientific method. Lack of reproducibility is a serious issue in
        contemporary research which we want to address at our workshop. To encourage authors to make their papers
        reproducible, and to reward the effort that reproducibility requires, we are introducing the GENEA Workshop
        Reproducibility Award. All short and long papers presented at the GENEA Workshop will be eligible for this
        award. Please note that it is the camera-ready version of the paper which will be evaluated for the reward.
        <br><br>
        The award is awarded to the paper with the greatest degree of reproducibility. The assessment criteria include:
        <ul>
          <li>ease of reproduction (ideal: just works, if there is code - it is well documented and we can run it)</li>
          <li>extent (ideal: all results can be verified)</li>
          <li>data accessibility (ideal: all data used is publicly available)</li>
        </ul>

        <!-- This year saw exceptional efforts in reproducibility across submissions, raising the overall standard of transparency and reliability in research.  
        <br>
        <div style="text-align: center; margin-top: 30px;">
          The runner-up for this year's Reproducibility Award is: <a href="https://openreview.net/forum?id=m6FDIP5o4M" target="_blank"><b>Benchmarking Speech-Driven Gesture Generation Models for Generalization to Unseen Voices and Noisy Environments</b></a> by
          <i>Johsac Isbac GÃ³mez SÃ¡nchez, Kevin Adier Inofuente Colque, Leonardo Boulitreau de Menezes Martins Marques, Paula Dornhofer Paro Costa, and Rodolfo Luis Tonoli</i>.  
        </div>
        <br>
        <div style="text-align: center; margin-top: 30px;">
          This year's award is awarded to: <a href="https://openreview.net/forum?id=Iso5lbByDI" target="_blank"><b>Gesture Area Coverage to Assess Gesture Expressiveness and Human-Likeness</b></a> <br> by
          <i>Rodolfo Luis Tonoli, Paula Dornhofer Paro Costa, Leonardo Boulitreau de Menezes Martins Marques, and Lucas Hideki Ueda</i>. <br><br>
          <img src="/2025/img/award.JPG" alt="reproducibility award" width=600>
        </div>
        <br><br> -->
    </div>

    </section>

    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="invited-speakers">
      <div class="w-100">
        <h2 class="mb-5">Invited speakers</h2>

        <h3 class="mt-5" id="catherine">Catherine Pelachaud</h3>
        <div class="row">
          <div class="col-2"><a href="http://chronos.isir.upmc.fr/~pelachaud/" target="_blank"><img src="/2025/img/2024_catherine_pelachaud.jpg"
                style=" margin-right: 30px; margin-bottom: 10px" class="img-fluid rounded" alt="Catherine Pelachaud"></a>
          </div>
          <div class="col-10">
            <h5>Biography</h5>
            Catherine Pelachaud (CNRS-ISIR) is Director of Research in the laboratory ISIR, Sorbonne University. Her research
            interest includes socially interactive agent, nonverbal communication (face, gaze, gesture and touch), and adaptive
            mechanisms in interaction. <br/><br/>
            
            With her research team, she has been developing an interactive virtual agent platform,
            Greta, that can display emotional and communicative behaviors. She is co-editor of the ACM handbook on socially
            interactive agents (2021-22).
        
            <br>
            <br>
            <h5>Talk</h5> (Coming soon)
          </div>
        </div>

        <h3 class="mt-5" id="asli">Asli Ozyurek</h3>
        <div class="row">
          <div class="col-2"><a href="https://www.mpi.nl/people/ozyurek-asli"> <img src="/2025/img/Asli_Ozyurek.jfif"
                style=" margin-right: 30px; margin-bottom: 10px" class="img-fluid rounded" alt="Asli Ozyurek"></a></div>
          <div class="col-10">
            <h5>Biography</h5>
            Asli Ã–zyÃ¼rek, received a joint PhD in Linguistics and Psychology from the University of Chicago. She is currently the
            Director of Multimodal Language Department at the Max Planck Institute for Psycholinguistics and is also a Professor and
            PI at Donders Institute for Brain Cognition and Behavior at Radboud University. <br /><br />
            
            Ã–zyÃ¼rek investigates the inherently and
            universal multimodal nature of human language capacity as one of its adaptive design features. To do so she studies how
            humans and machines produce and process gestures with spoken language and sign languages; how brain supports multimodal
            language;how typologically different spoken and signed languages pattern their structures and how cognition, learning
            constraints and communicative pressures of interaction shape multimodal language, its acquisition and evolution as an
            adaptive system. She uses a variety of methodologies such as behavioral and kinematic analyses of multimodal linguistic
            structures, eye tracking, machine learning, virtual reality and brain imaging to understand the complex multimodal
            nature of human language capacity and ho it is recruited in different communicative settings. <br /><br />
            
            She has received many prestigious grants from NSF, NIH, Dutch Science Foundation (VIDI;VICI), ERC, EU Commision and 
            Turkish Science Foundation and is an elected fellow of the Cognitive Society and Academia Europea.
          
            <br>
            <br>
            <h5>Talk</h5> (Coming soon)
          </div>
        </div>
      </div>
    </section>



  <!-- <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="accepted-papers">
      <div class="w-100">
        <h2 class="mb-5">Accepted papers</h2>

        <p>
        <h4><a href="https://openreview.net/forum?id=6opmqWhlwF" target="_blank">Towards interpretable co-speech gestures synthesis using STARGATE</a></h4>
        <i> Louis Abel, Vincent Colotte and Slim Ouni</i><br><br>
        </p>
        <hr>

        <p>
        <h4><a href="https://openreview.net/forum?id=hp9isRQZqr" target="_blank">Qualitative study of gesture annotation corpus: Challenges and perspectives</a></h4>
        <i>MickaÃ«lla Grondin Verdon, Domitille Caillat and Slim Ouni</i><br><br>
        </p>
        <hr>

        <p>
        <h4><a href="https://openreview.net/forum?id=1G4fIPocY2" target="_blank">Gesture Evaluation in Virtual Reality</a></h4>
        <i>Anna Deichler, Jonas Beskow and Axel Wiebe Werner</i><br><br>
        </p>
        <hr>

        <p>
        <h4><a href="https://openreview.net/forum?id=Iso5lbByDI" target="_blank">Gesture Area Coverage to Assess Gesture Expressiveness and Human-Likeness</a></h4>
        <i>Rodolfo Luis Tonoli, Paula Dornhofer Paro Costa, Leonardo Boulitreau de Menezes Martins Marques and Lucas Hideki Ueda</i><br><br>
        </p>

        <p>
        <h4><a href="https://openreview.net/forum?id=m6FDIP5o4M" target="_blank">Benchmarking Speech-Driven Gesture Generation Models for Generalization to Unseen Voices and Noisy Environments</a></h4>
        <i> Johsac Isbac GÃ³mez SÃ¡nchez, Kevin Adier Inofuente Colque, Leonardo Boulitreau de Menezes Martins Marques, Paula Dornhofer Paro Costa and Rodolfo Luis Tonoli</i><br><br>
        </p>
        <hr>

      </div>
    </section> -->





    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="organising-committee">
      <div class="w-100">
        <h2 class="mb-5">Organising committee</h2>
        <p>
          The main contact address of the workshop is: <a
            href="mailto:genea-contact@googlegroups.com">genea-contact@googlegroups.com</a>. <br> <br>
        </p>
        <h4>Workshop organisers</h4>

        <div class="row">

          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2025/img/taras.jpg" class="img-fluid rounded" alt="Taras Kucherenko">
              </div>
              <div class="col-7">
                <a href="https://svito-zar.github.io/" target="_blank" style="font-weight: bold;">Taras Kucherenko</a>
                <br>
                Electronic Arts (EA) <br> Sweden
              </div>
            </div>
            <hr>
          </div>

          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2025/img/youngwoo.jpg" class="img-fluid rounded" alt="Youngwoo Yoon">
              </div>
              <div class="col-7">

                <a href="https://youngwoo-yoon.github.io/" target="_blank"
                  style="font-weight: bold;">Youngwoo Yoon</a>
                <br>ETRI <br> South Korea
              </div>
            </div>
            <hr>
          </div>

        </div>


        <div class="row">

          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2025/img/rajmund.png" class="img-fluid rounded" alt="Rajmund Nagy">
              </div>
              <div class="col-7">

                <a href="https://nagyrajmund.github.io/" target="_blank" style="font-weight: bold;">Rajmund Nagy</a>
                <br>
                KTH Royal Institute of Technology <br> Sweden


              </div>
            </div>
            <hr>
          </div>

          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2025/img/gustav.jpeg" class="img-fluid rounded" alt="Gustav Eje Henter">
              </div>
              <div class="col-7">

                <a href="https://people.kth.se/~ghe/" target="_blank" style="font-weight: bold;">Gustav Eje Henter</a>
                <br>
                KTH Royal Institute of Technology <br> 
                Motorica AB <br>
                Sweden


              </div>
            </div>
            <hr>
          </div>

        </div>

        <div class="row">

          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2025/img/alice.jpg" width="100%" class="img-fluid rounded" alt="Alice Delbosc">
              </div>
              <div class="col-7">
                <a href="https://pageperso.lis-lab.fr/alice.delbosc/" target="_blank" style="font-weight: bold;">Alice Delbosc</a>
                <br>
                Davi, The Humanizers <br> France
              </div>
            </div>
            <hr>
          </div>

          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2025/img/laura.jfif" class="img-fluid rounded" alt="Laura Hensel">
              </div>
              <div class="col-7">

                <a href="https://scholar.google.co.uk/citations?user=1R8GM7sAAAAJ&hl=en" target="_blank" style="font-weight: bold;">Laura Hensel</a>
                <br>
                University of Glasgow <br> Scotland, UK
              </div>
            </div>
            <hr>
          </div>

        </div>

        <div class="row">

          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2025/img/oyaceliktutan.jfif" width="100%" class="img-fluid rounded" alt="Oya Celiktutan">
              </div>
              <div class="col-7">
                <a href="https://nms.kcl.ac.uk/oya.celiktutan/" target="_blank" style="font-weight: bold;">Oya Celiktutan</a>
                <br>
                King's College London <br> United Kingdom
              </div>
            </div>
            <hr>
          </div>

        </div>

      </div>
    </section>
    
    <!-- <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="program-committee">
      <div class="w-100">
        <h2 class="mb-5">Program committee</h2>
        <ul>
                  <li>None yet.</li>
                </ul>
      </div>

    </section> -->
    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="join-our-community">
      <div class="w-100">
        <h2 class="mb-5">Join our community</h2>
        <p>Join our <b>Slack</b> space dedicated to the gesture generation research community. 
          In order to ensure the security and integrity of our community, we kindly ask you to fill out
          <a href="https://docs.google.com/forms/d/e/1FAIpQLSfFq0-lYGVwDVNmxlXEESk2_cYsvsRjzndR8Mu6QCGuFXavVA/viewform" style="font-weight: bold;"  target="_blank">this form</a>
          to obtain the invitation link.<br>
          Join us to share your work, data, interesting papers, questions, ideas, job opportunities and more.</p>

        <p>And keep up to date with the latest workshop news by following us on <a href="https://x.com/genea_workshop" style="font-weight: bold;"  target="_blank">X</a>.</p>
      </div>
 

  </div>

  <!-- Bootstrap core JavaScript -->
  <script src="/2025/vendor/jquery/jquery.min.js"></script>
  <script src="/2025/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="/2025/vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="/2025/js/iva.min.js"></script>

</body>

<!-- Panelbear -->
<script async src="https://cdn.panelbear.com/analytics.js?site=9bGH0f0hxBy"></script>
<script>
  window.panelbear = window.panelbear || function () { (window.panelbear.q = window.panelbear.q || []).push(arguments); };
  panelbear('config', { site: '9bGH0f0hxBy' });
</script>

</html>
