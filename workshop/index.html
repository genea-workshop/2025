<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>GENEA Workshop 2024
  </title>

  <!-- Bootstrap core CSS -->
  <link href="/2024/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
  <link href="/2024/vendor/fontawesome-free/css/all.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="/2024/css/iva.min.css" rel="stylesheet">
  <style>
    .announcement-box {
      background-color: rgba(125, 188, 255, 0.4);
      color: #777;
      font-size: 14px;
      line-height: 23px;
      padding: 13px 16px;
      text-align: justify;
      font-family:Arial, Helvetica, sans-serif;
      border-radius: 10px;
    }
  
    .announcement-box .badge {
    background-color: #0056b3;
    color: #fff;
    font-weight:bold;
    text-transform: uppercase;
    text-align: center;
    }
  </style>
</head>

<body id="page-top">

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">GENEA Challenge 2024</span>
      <!-- <span class="d-none d-lg-block">
        <img src="img/avatar.png" class="img-fluid img-profile rounded-circle mx-auto mb-5" alt="">

      </span> -->
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#home">Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#important-dates">Important dates</a>
        </li>

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#workshop-programme"><b>Workshop programme</b></a>
        </li>

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#call-for-papers">Call for papers</a>
        </li>

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#call-for-posters">Call for posters</a>
        </li>

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#reproducibility-award">Reproducibility Award</a>
        </li>

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#invited-speakers">Invited speakers</a>
        </li>

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#accepted-papers">Accepted papers</a>
        </li>

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#organising-committee">Organising committee</a>
        </li>
        <!--
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#program-committee">Program committee</a>
        </li>
      -->
      <li class="nav-item">
        <a class="nav-link js-scroll-trigger" href="#join-our-community">Join our community</a>
      </li>
      </ul>
    </div>
  </nav>


  <div class="container-fluid p-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="home">
      <div class="w-100">
        <div class="row">
          <div class="col-md-9 col-sm-12">
            <div> <img src="/2024/img/GENEA_logo.png" class="img-fluid rounded" class="mt-2" width=300 alt="GENEA"
                title="GENEA"> </div>
            <div>
              <h2 class="mb-2">
                Workshop 2024
              </h2>
            </div>

            <div class="subheading mb-5">Generation and Evaluation of Non-verbal Behaviour for Embodied Agents</div>

            <!-- <p class="mb-5">
            <div class="col-sm-12 col-md-12">
              <div class="row">
              <div class="announcement-box">
                <span class="badge">Announcement</span>
                üì¢ <strong>Call for Posters</strong> now open! Submit your work by <strong>September 30, 2024</strong>.
                    <a href="#call-for-posters">Click here for more details</a>.
              </div>
              </div>
            </div>
            </p> -->

            <p class="mb-5">
              <b>Official <a href="https://icmi.acm.org/2024/">ICMI 2024</a> Workshop ‚Äì November 4, 2024 (in person)
              </b><br><br>


              The GENEA (Generation and Evaluation of Non-verbal Behaviour for Embodied Agents) Workshop
              2024 aims at bringing together researchers that use different methods for non-verbal-behaviour generation
              and evaluation, and hopes to stimulate the discussions on how to improve both the
              generation methods and the evaluation of the results. We invite all interested researchers to submit a
              paper related to their
              work in the area and to participate in the workshop. This is the fifth installment of the GENEA Workshop,
              for more information about the 2023 installment, please go <a
                href="https://genea-workshop.github.io/2023/" target="_blank">here</a>.<br><br>


            </p>
            <div class="row justify-content-center">

              <img src="/2024/img/avatar.png" class="img-fluid rounded" class="mt-2" width=300 alt="">
            </div>
          </div>
          <div class="col-md-3 d-none d-md-block">
            <a class="twitter-timeline" href="https://twitter.com/genea_workshop?ref_src=twsrc%5Etfw">Tweets by genea_workshop</a>
            <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
          </div>
        </div>
      </div>

    </section>

    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="important-dates">
      <div class="w-100">
        <h2 class="mb-5">Important dates </h2>
        <p>Submission Deadlines: All deadlines are set at the end of the day, <a
            href="https://en.wikipedia.org/wiki/Anywhere_on_Earth">Anywhere on Earth (AoE)</a></p>
        <div class="row">
          <div class="col">July 8, 2024</div>
          <div class="col">Paper abstract deadline</div>
        </div>
        <div class="row">
          <div class="col">July 10, 2024</div>
          <div class="col">Submission deadline</div>
        </div>
        <div class="row">
          <div class="col">July 31, 2024</div>
          <div class="col">Notification of paper acceptance</div>
        </div>
        <div class="row">
          <div class="col">Aug 14, 2024</div>
          <div class="col">Camera-ready deadline</div>
        </div>
        <div class="row">
          <div class="col">Sept 30, 2024</div>
          <div class="col">Poster-session submission deadline</div>
        </div>
        <!-- <div class="row">
          <div class="col">September 1, 2023</div>
          <div class="col">Notification of poster acceptance</div>
        </div> -->
        <div class="row">
          <div class="col">Nov 4, 2024</div>
          <div class="col">In-person workshop at ICMI</div>
        </div>

    </section>

    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="workshop-programme">
      <div class="w-100">
        <h2 class="mb-5">Planned Workshop programme</h2>
        <h4>ALL TIMES IN SAN JOSE' LOCAL TIMEZONE (UTC-6)</h4>
        <div>The Workshop presentations will take place at ICMI in San Jos√© on November 4th.</div>
        
        <div class="row">
          <div class="col">09:30&nbsp;-&nbsp;09:40</div>
          <div class="col-10"><b>Opening statement</b></div>
        </div>

        <div class="row">
          <div class="col">09:40&nbsp;-&nbsp;10:30</div>
          <div class="col-10"><b>Keynote presentation by Stacy Marsella (Northeastern's Khoury College of Computer Sciences, Boston)</b></div>
        </div>

        <div class="row">
          <div class="col">10:30&nbsp;-&nbsp;11:30</div>
          <div class="col-10"><b>Workshop paper presentations part I</b></div>
        </div>
        <div class="row">
          <ul style="list-style: none">
            <li><span style="margin-right: 10px;"> </span> Gesture Evaluation in Virtual Reality (Deichler et al.)</li>
            <li><span style="margin-right: 10px;"> </span> Gesture Area Coverage to Assess Gesture Expressiveness and Human-Likeness (Tonoli et al.)</li>
            <li><span style="margin-right: 10px;"> </span> Benchmarking Speech-Driven Gesture Generation Models for Generalization to Unseen Voices and Noisy Environments (G√≥mez S√°nchez et al.)</li>
          </ul>
        </div>
        
        <div class="row">
          <div class="col">11:30&nbsp;-&nbsp;13:00</div>
          <div class="col-10"><b>Lunch break</b></div>
        </div>

        <div class="row">
          <div class="col">13:00&nbsp;-&nbsp;13:50</div>
          <div class="col-10"><b>Keynote presentation by Yukiko Nakano (Seikei University, Tokyo)</b></div>
        </div>

        <div class="row">
          <div class="col">13:50&nbsp;-&nbsp;14:30</div>
          <div class="col-10"><b>Break / Poster session</b></div>
        </div>

        <div class="row">
          <div class="col">14:30&nbsp;-&nbsp;15:10</div>
          <div class="col-10"><b>Workshop paper presentations part II</b></div>
        </div>
        <div class="row">
          <ul style="list-style: none">
            <li><span style="margin-right: 10px;"> </span> Towards interpretable co-speech gestures synthesis using STARGATE (Abel et al.)</li>
            <li><span style="margin-right: 10px;"> </span> Qualitative study of gesture annotation corpus: Challenges and perspectives (Grondin Verdon et al.)</li>
          </ul>
        </div>

        <div class="row">
          <div class="col"> 15:10&nbsp;-&nbsp;16:10</a> </div>
          <div class="col-10"><b>Panel discussion</b></div>
        </div>
        <div class="row">
          <ul style="list-style: none">
            <li><span style="margin-right: 10px;"> </span>Sean Andrist, Stacy Marsella, Yukiko Nakano and Yaser Sheikh</li>
          </ul>
        </div>
      
        <div class="row">
          <div class="col">16:10&nbsp;-&nbsp;16:30</div>
          <div class="col-10"><b>Break</b></div>
        </div>

        <div class="row">
          <div class="col">16:30&nbsp;-&nbsp;16:50</div>
          <div class="col-10"><b>GENEA Leaderboard presentation</b></div>
        </div>

        <div class="row">
          <div class="col">16:50&nbsp;-&nbsp;17:50</div>
          <div class="col-10"><b>Group discussion</b></div>
        </div>

        <div class="row">
          <div class="col">17:50&nbsp;-&nbsp;18:00</div>
          <div class="col-10"><b>Closing remarks (announce award winner)</b></div>
        </div>

      </div>

    </section>

    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="call-for-papers">

      <div class="w-100">
        <h2 class="mb-5">Call for papers</h2>

        <div class="iva-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="iva-content">
            <p> GENEA 2024 is the fifth GENEA Workshop and an official workshop of ACM ICMI ‚Äô24, which will take place in San Jos√©, 
              Costa Rica. Accepted paper submissions will be included in the adjunct ACM ICMI proceedings.</p>
            <p> Generating non-verbal behaviours, such as gesticulation, facial expressions and gaze, is of great importance 
              for natural interaction with embodied agents such as virtual agents and social robots. At present, behaviour generation 
              is typically powered by rule-based systems, data-driven approaches, and their hybrids. For evaluation, both objective and 
              subjective methods exist, but their application and validity are frequently a point of contention.
            </p>

            <p>This workshop asks, ‚ÄúWhat will be the behaviour-generation methods of the future? And how can we evaluate these methods 
              using meaningful objective and subjective metrics?‚Äù The aim of the workshop is to bring together researchers working on the 
              generation and evaluation of non-verbal behaviours for embodied agents to discuss the future of this field. To kickstart these 
              discussions, we invite all interested researchers to submit a paper for presentation at the workshop.
            </p>

            <h4>Paper topics include (but are not limited to) the following</h4>
            <ul>
              <li>Automated synthesis of facial expressions, gestures, and gaze movements</li>
              <li>Audio- and music-driven nonverbal behaviour synthesis</li>
              <li>Closed-loop nonverbal behaviour generation (from perception to action)</li>
              <li>Nonverbal behaviour synthesis in two-party and group interactions</li>
              <li>Emotion-driven and stylistic nonverbal behaviour synthesis</li>
              <li>New datasets related to nonverbal behaviour</li>
              <li>Believable nonverbal behaviour synthesis using motion-capture and 4D scan data</li>
              <li>Multi-modal nonverbal behaviour synthesis</li>
              <li>Interactive/autonomous nonverbal behavior generation</li>
              <li>LLMs and foundation models in the context of non-verbal behaviour synthesis</li>
              <li>Subjective and objective evaluation methods for nonverbal behaviour synthesis</li>
              <li>Guidelines for nonverbal behaviours in human-agent interaction</li>
            </ul>
            <p>We will accept <b>long</b> (max 8 pages) and <b>short</b> (max 4 pages) paper submissions, all in the same double-column <a href="https://icmi.acm.org/2024/guidelines/">ACM 
              conference format</a> as used by ICMI. Pages containing only references do not count toward the page limit for any of the paper types. 
              Submissions should be formatted for double-blind review made in PDF format through OpenReview.</p>
            
            <p><b>Submission site:</b><a
                href="https://openreview.net/group?id=ACM.org/ICMI/2024/Workshop/GENEA"> https://openreview.net/group?id=ACM.org/ICMI/2024/Workshop/GENEA</a>
            </p>
            <p>To encourage authors to make their work reproducible and reward the effort that this requires, we have
              introduced the <a class="js-scroll-trigger" href="#reproducibility-award">GENEA Workshop Reproducibility Award</a>.
            </p>

            <p>We will also host an <b>open poster session</b> for advertising your late-breaking results and already-published work to the community. 
              No paper submission is needed to participate in the poster session, and these posters will not be part of any proceedings (non archival). 
              Submission guidelines for the poster session will be available on the workshop website.
            </p>
          </div>
        </div>
      </div>
    </section>


    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="call-for-posters">
    
      <div class="w-100">
        <h2 class="mb-5">Call for posters</h2>
    
        <div class="iva-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="iva-content">
            <p>The GENEA Workshop at ACM ICMI 2024 will host an open poster session for advertising your late-breaking
              results and recently-published work to the community. Only a poster submission is required, no paper
              submission is needed to participate in the poster session, and these posters will not be part of any
              proceedings (i.e., non-archival). However, poster presentation does require a valid registration with ICMI to
              attend the workshop, and is subject to space constraints.</p>
    
            <h4>Paper topics include (but are not limited to) the following</h4>
            <ul>
              <li>Automated synthesis of facial expressions, gestures, and gaze movements</li>
              <li>Audio- and music-driven nonverbal behaviour synthesis</li>
              <li>Closed-loop nonverbal behaviour generation (from perception to action)</li>
              <li>Nonverbal behaviour synthesis in two-party and group interactions</li>
              <li>Emotion-driven and stylistic nonverbal behaviour synthesis</li>
              <li>New datasets related to nonverbal behaviour</li>
              <li>Believable nonverbal behaviour synthesis using motion-capture and 4D scan data</li>
              <li>Multi-modal nonverbal behaviour synthesis</li>
              <li>Interactive/autonomous nonverbal behavior generation</li>
              <li>LLMs and foundation models in the context of non-verbal behaviour synthesis</li>
              <li>Subjective and objective evaluation methods for nonverbal behaviour synthesis</li>
              <li>Guidelines for nonverbal behaviours in human-agent interaction</li>
            </ul>
    
            <h3>Poster guidelines</h3>
            <ul>
              <li>Poster format: 1-page poster (no larger than A0 size; portrait is recommended). There is no specific
                template. The poster can be designed as you want.
              </li>
              <li>How to submit: Please submit your poster draft (in PDF format) and/or poster abstract <a
                  href="https://forms.gle/mxJ6uTGbXS8gb9169">here (https://forms.gle/mxJ6uTGbXS8gb9169)</a>. We will
                acknowledge your submission within 24 hours. The submission deadline is 23:59, September 30, 2024 (Anywhere
                on Earth timezone). We will get back to you no later than October 15 to let you know if we are able to
                accommodate your poster at the event.</li>
            </ul>
          </div>
        </div>
      </div>
    </section>

    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="reproducibility-award">

      <div class="w-100">
        <h2 class="mb-5">Reproducibility Award</h2>
        Reproducibility is a cornerstone of the scientific method. Lack of reproducibility is a serious issue in
        contemporary research which we want to address at our workshop. To encourage authors to make their papers
        reproducible, and to reward the effort that reproducibility requires, we are introducing the GENEA Workshop
        Reproducibility Award. All short and long papers presented at the GENEA Workshop will be eligible for this
        award. Please note that it is the camera-ready version of the paper which will be evaluated for the reward.
        <br><br>
        The award is awarded to the paper with the greatest degree of reproducibility. The assessment criteria include:
        <ul>
          <li>ease of reproduction (ideal: just works, if there is code - it is well documented and we can run it)</li>
          <li>extent (ideal: all results can be verified)</li>
          <li>data accessibility (ideal: all data used is publicly available)</li>
        </ul>
      </div>

    </section>

    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="invited-speakers">
      <div class="w-100">
        <h2 class="mb-5">Invited speakers</h2>

        <h3 class="mt-5" id="rachel">Yukiko I. Nakano</h3>
        <div class="row">
          <div class="col-2"><a href="https://www.ci.seikei.ac.jp/nakano/index_e.html"><img src="/2024/img/YukikoNakano.jpg"
                style=" margin-right: 30px; margin-bottom: 10px" class="img-fluid rounded" alt="Yukiko I. Nakano"></a>
          </div>
          <div class="col-10">
            <h5>Biography</h5>
            Yukiko I. Nakano is a Professor in the Department of Computer and Information Science at Seikei University, Tokyo, where
            she leads the Intelligent User Interface Laboratory (IUI-lab). She received her M.S. in Media Arts and Sciences from the
            Massachusetts Institute of Technology (MIT) and her Ph.D. in Information Science and Technology from the University of
            Tokyo. <br/>
            
            Her research focuses on social signal processing to establish machine learning models for estimating the characteristics
            of multimodal and multiparty interactions, applying these models to human-agent interactions such as conversational
            agents and communication robots. <br/>
            
            Her research interests include social signal processing, multimodal machine learning, nonverbal behavior modeling, and
            embodied conversational agents (ECAs). <br/>
            
            She has served as Steering Committee Chair for the ACM International Conference on Multimodal Interaction (ICMI),
            co-chaired major conferences such as ICMI2016 and IVA2012, and co-organized the Workshop on Eye Gaze in Intelligent
            Human Machine Interaction from 2011 to 2014. <br/>

            <!-- <br>
            <br>
            <h5>Talk</h5> (Coming soon) -->
          </div>
        </div>

        <h3 class="mt-5" id="stacy_c_matsella">Stacy C. Marsella</h3>
        <div class="row">
          <div class="col-2"><a href="https://www.khoury.northeastern.edu/people/stacy-c-marsella/"> <img src="/2024/img/Marsella_Stacy2.jpg"
                style=" margin-right: 30px; margin-bottom: 10px" class="img-fluid rounded" alt="Stacy C. Marsella"></a></div>
          <div class="col-10">
            <h5>Biography</h5>
            Stacy Marsella is a professor at the Khoury College of Computer Sciences with a joint appointment in psychology.
            Prior to joining Northeastern, he was a research professor in the Department of Computer Science at the University
            of Southern California and a research director at the Institute for Creative Technologies. Previously, he held
            positions at USC‚Äôs Information Sciences Institute (1996-2009) and Bell Labs (1995-1996). <br/>
        
            Marsella‚Äôs multidisciplinary research is grounded in the computational modeling of human cognition, emotion, and
            social behavior, as well as the evaluation of those models. Beyond its relevance to understanding human behavior,
            the work has seen numerous applications, including health interventions, social skills training, and planning
            operations. His applied work includes frameworks for large-scale social simulations of towns and a range of
            techniques and tools for creating virtual humans, facsimiles of people that can engage in face-to-face interactions.<br/>
        
            Marsella has served as a general chair of Autonomous Agents and Multiagent Systems and chair of Intelligent Virtual
            Agents. In 2010, he received an ACM SIIGART career award for his contributions to agent research. He is an associate
            editor of the IEEE Transactions on Affective Computing, a board member of the International Foundation for
            Autonomous Agents and Multiagent Systems, and on the steering committee for Intelligent Virtual Agents. He is a
            fellow of the Society of Experimental Social Psychologists and a member of the Association for the Advancement of
            Artificial Intelligence and the International Society for Research on Emotions.<br/>
          
            <br>
            <br>
            <h5>Talk: Gesture Selection and Large Language Models</h5>
            Abstract: Co-speech gestures convey a wide variety of meanings and can play an important role in virtual human
            interactions with people. Thus, it is often critical for a virtual human to use appropriate gestures. However, the
            automation of a virtual human‚Äôs gesture selection process faces a range of challenges. The form of a gesture conveys
            meaning related in varying ways to the spoken dialog. The form is also tied to the larger interaction context and the
            role of the speaker in that interaction. Comedians on stage, politicians during a speech and clinicians in a therapy
            session use different gestural forms to achieve different ends. Gesture generation techniques have attempted to address
            such challenges in varied ways from fully automated, data-driven techniques to approaches that require varying degrees
            of manual crafting. In this talk, I discuss the challenges of gesture selection, with a specific focus on metaphoric
            gestures that convey meaning and on tailoring the gesture selection to an interaction context. I then cover our group‚Äôs
            efforts to realize and evaluate a gesture selection approach that leverages the capabilities of Large Language Models to
            address these challenges.
          </div>
        </div>
      </div>
    </section>



  <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="accepted-papers">
      <div class="w-100">
        <h2 class="mb-5">Accepted papers</h2>

        <p>
        <h4><a href="https://openreview.net/forum?id=6opmqWhlwF" target="_blank">Towards interpretable co-speech gestures synthesis using STARGATE</a></h4>
        <i> Louis Abel, Vincent Colotte and Slim Ouni</i><br><br>
        </p>
        <hr>

        <p>
        <h4><a href="https://openreview.net/forum?id=hp9isRQZqr" target="_blank">Qualitative study of gesture annotation corpus: Challenges and perspectives</a></h4>
        <i>Micka√´lla Grondin Verdon, Domitille Caillat and Slim Ouni</i><br><br>
        </p>
        <hr>

        <p>
        <h4><a href="https://openreview.net/forum?id=1G4fIPocY2" target="_blank">Gesture Evaluation in Virtual Reality</a></h4>
        <i>Anna Deichler, Jonas Beskow and Axel Wiebe Werner</i><br><br>
        </p>
        <hr>

        <p>
        <h4><a href="https://openreview.net/forum?id=Iso5lbByDI" target="_blank">Gesture Area Coverage to Assess Gesture Expressiveness and Human-Likeness</a></h4>
        <i>Rodolfo Luis Tonoli, Paula Dornhofer Paro Costa, Leonardo Boulitreau de Menezes Martins Marques and Lucas Hideki Ueda</i><br><br>
        </p>

        <p>
        <h4><a href="https://openreview.net/forum?id=m6FDIP5o4M" target="_blank">Benchmarking Speech-Driven Gesture Generation Models for Generalization to Unseen Voices and Noisy Environments</a></h4>
        <i> Johsac Isbac G√≥mez S√°nchez, Kevin Adier Inofuente Colque, Leonardo Boulitreau de Menezes Martins Marques, Paula Dornhofer Paro Costa and Rodolfo Luis Tonoli</i><br><br>
        </p>
        <hr>

      </div>
    </section>





    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="organising-committee">
      <div class="w-100">
        <h2 class="mb-5">Organising committee</h2>
        <p>
          The main contact address of the workshop is: <a
            href="mailto:genea-contact@googlegroups.com">genea-contact@googlegroups.com</a>. <br> <br>
        </p>
        <h4>Workshop organisers</h4>

        <div class="row">


          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2024/img/youngwoo.jpg" class="img-fluid rounded" alt="Youngwoo Yoon">
              </div>
              <div class="col-7">

                <a href="https://sites.google.com/view/youngwoo-yoon/" target="_blank"
                  style="font-weight: bold;">Youngwoo Yoon</a>
                <br>ETRI <br> South Korea


              </div>
            </div>
            <hr>
          </div>
          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2024/img/taras.jpg" class="img-fluid rounded" alt="Taras Kucherenko">
              </div>
              <div class="col-7">
                <a href="https://svito-zar.github.io/" target="_blank" style="font-weight: bold;">Taras Kucherenko</a>
                <br>
                Electronic Arts (EA) <br> Sweden

              </div>
            </div>
            <hr>

          </div>
        </div>


        <div class="row">

          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2024/img/rajmund.png" class="img-fluid rounded" alt="Rajmund Nagy">
              </div>
              <div class="col-7">

                <a href="https://nagyrajmund.github.io/" target="_blank" style="font-weight: bold;">Rajmund Nagy</a>
                <br>
                KTH Royal Institute of Technology <br> Sweden


              </div>
            </div>
            <hr>
          </div>

          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2024/img/teodor.jfif" class="img-fluid rounded" alt="Teodor Nikolov">
              </div>
              <div class="col-7">

                <a href="https://teonikolov.github.io/" target="_blank" style="font-weight: bold;">Teodor Nikolov</a>
                <br>
                Unreal Engine <br> Netherlands


              </div>
            </div>
            <hr>
          </div>



        </div>

        <div class="row">

          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2024/img/gustav.jpeg" class="img-fluid rounded" alt="Gustav Eje Henter">
              </div>
              <div class="col-7">

                <a href="https://people.kth.se/~ghe/" target="_blank" style="font-weight: bold;">Gustav Eje Henter</a>
                <br>
                KTH Royal Institute of Technology <br> 
                Motorica AB <br>
                Sweden


              </div>
            </div>
            <hr>
          </div>

          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2024/img/alice.jpg" width="100%" class="img-fluid rounded" alt="Alice Delbosc">
              </div>
              <div class="col-7">
                <a href="https://pageperso.lis-lab.fr/alice.delbosc/" target="_blank" style="font-weight: bold;">Alice Delbosc</a>
                <br>
                Davi, The Humanizers <br> France
              </div>
            </div>
            <hr>
          </div>



        </div>

      </div>
    </section>
    
    <!-- <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="program-committee">
      <div class="w-100">
        <h2 class="mb-5">Program committee</h2>
        <ul>
                  <li>None yet.</li>
                </ul>
      </div>

    </section> -->
    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="join-our-community">
      <div class="w-100">
        <h2 class="mb-5">Join our community</h2>
        <p>Join our <b>Slack</b> space dedicated to the gesture generation research community. 
          In order to ensure the security and integrity of our community, we kindly ask you to fill out
          <a href="https://docs.google.com/forms/d/e/1FAIpQLSfFq0-lYGVwDVNmxlXEESk2_cYsvsRjzndR8Mu6QCGuFXavVA/viewform" style="font-weight: bold;">this form</a>
          to obtain the invitation link.<br>
          Join us to share your work, data, interesting papers, questions, ideas, job opportunities and more.</p>

        <p>And keep up to date with the latest workshop news by following us on <a href="https://x.com/genea_workshop" style="font-weight: bold;">X</a>.</p>
      </div>
 

  </div>

  <!-- Bootstrap core JavaScript -->
  <script src="/2024/vendor/jquery/jquery.min.js"></script>
  <script src="/2024/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="/2024/vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="/2024/js/iva.min.js"></script>

</body>

<!-- Panelbear -->
<script async src="https://cdn.panelbear.com/analytics.js?site=9bGH0f0hxBy"></script>
<script>
  window.panelbear = window.panelbear || function () { (window.panelbear.q = window.panelbear.q || []).push(arguments); };
  panelbear('config', { site: '9bGH0f0hxBy' });
</script>

</html>
